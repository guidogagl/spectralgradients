{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /home/guido/github/spectralgradients\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import copy\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable GPU. \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import os\n",
    "os.chdir( \"/home/guido/github/spectralgradients\" )\n",
    "print( \"Current working directory: \", os.getcwd() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and model\n",
    "\n",
    "from collections import OrderedDict\n",
    "from src.synt_data import SyntDataset, CLASS_DESC\n",
    "\n",
    "data = SyntDataset(CLASS_DESC)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "loader = DataLoader(data, batch_size=128, num_workers=8)\n",
    "\n",
    "x_batch, y_batch = next(iter(loader))\n",
    "\n",
    "\n",
    "from src.train.model import TimeModule\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "fn = TimeModule.load_from_checkpoint(\"output/model/checkpoint/epoch=19-step=21686-val_acc=0.93.ckpt\", n_classes = data.n_class).eval()\n",
    "fn = nn.Sequential(OrderedDict([(\"fn\", fn), (\"softmax\", nn.Softmax(dim=-1))])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1563 [00:00<?, ?it/s]\u001b[32m2024-11-24 13:28:41.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mEvaluating Saliency with IROF\u001b[0m\n",
      "100%|██████████| 10/10 [00:00<00:00, 170.86it/s]\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.0976)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.explainer_wrapper import explainer_wrapper, localization, lle, irof\n",
    "from loguru import logger \n",
    "from tqdm.autonotebook import tqdm\n",
    "method = {\n",
    "    \"method\": \"Saliency\",\n",
    "}\n",
    "\n",
    "method[\"model\"] = fn\n",
    "\n",
    "method[\"irof\"] = []\n",
    "method[\"lle\"] = []\n",
    "\n",
    "for i in tqdm(torch.arange(0, len(data), batch_size).long()):\n",
    "\n",
    "    if i + batch_size > len(data):\n",
    "        batch_size = len(data) - 1\n",
    "\n",
    "    x_batch, m_batch, y_batch = [], [], []\n",
    "\n",
    "    for j in range(i, i + batch_size):\n",
    "\n",
    "        x, m, y = data.__getitem__(j, True)\n",
    "\n",
    "        # last class is for the baseline \n",
    "        if y == data.n_class - 1:\n",
    "            continue\n",
    "\n",
    "        x_batch += [x]\n",
    "        m_batch += [m]\n",
    "        y_batch += [y]\n",
    "\n",
    "\n",
    "    x_batch = torch.stack(x_batch)\n",
    "    m_batch = torch.stack(m_batch)\n",
    "    y_batch = torch.stack(y_batch)\n",
    "\n",
    "    method[\"model\"] = fn\n",
    "\n",
    "    method[\"inputs\"] = x_batch\n",
    "    method[\"targets\"] = y_batch\n",
    "\n",
    "    explainer, a_batch = explainer_wrapper(**method)\n",
    "\n",
    "\n",
    "\n",
    "    logger.info( f\"Evaluating {method[\"method\"]} with IROF\")\n",
    "    method[\"irof\"] += [ irof(\n",
    "        explainer=explainer,\n",
    "        model=fn,\n",
    "        x=x_batch,\n",
    "        y=y_batch,\n",
    "        attr=a_batch,\n",
    "        mask=m_batch,\n",
    "    ) ]\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "    logger.info( f\"Evaluating {method[\"method\"]} with LLE\")\n",
    "    method[\"lle\"] += [ lle(\n",
    "        explainer= explainer,\n",
    "        model=fn,\n",
    "        x=x_batch,\n",
    "        y=y_batch,\n",
    "        attr=a_batch,\n",
    "        mask=m_batch,\n",
    "    ).item() ]\n",
    "\n",
    "method[\"irof\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
